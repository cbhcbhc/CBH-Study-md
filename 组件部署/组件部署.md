# 清理linux缓存

```sh
echo 3 > /proc/sys/vm/drop_caches
```



# nacos问题

你可以在启动容器时添加健康检查指令，可以使用`HEALTHCHECK`指令。`HEALTHCHECK`指令是Docker 1.12版本引入的新功能，它可以定期检查容器的健康状态，并在容器状态改变时通知Docker。在Dockerfile中使用`HEALTHCHECK`指令可以让Docker自动检测容器的健康状态，并根据检测结果自动重启容器或者通知运维人员。

例如，在Dockerfile中添加以下命令：

```
复制代码HEALTHCHECK --interval=30s --timeout=10s \
  CMD curl -f http://localhost:8848/nacos/health/check || exit 1
```

这个命令指定了健康检查的方式和检查的间隔时间。其中，`--interval`参数指定检查的时间间隔，单位为秒；`--timeout`参数指定检查的超时时间，单位为秒；`CMD`后面指定了检查命令，这里使用了curl命令来检查Nacos的健康状态。如果检查成功，则返回0，否则返回1。

在运行容器时，可以添加`--health-cmd`参数和`--health-interval`参数来指定健康检查的方式和间隔时间。例如：

```
复制代码docker run --name nacos -p 8848:8848 --health-cmd="curl -f http://localhost:8848/nacos/health/check || exit 1" --health-interval=30s -d nacos/nacos-server
```

这样就可以添加健康检查指令来保证Nacos Server容器的健康状态。



# 扩容linux

`df -h`:查看磁盘使用情况

```sh
/dev/mapper/centos-root   17G   17G  974M  95% /
```



```tex
看到你的根分区已经使用了 95% 的空间，我们需要扩大根分区的大小。具体步骤如下：

首先，使用 sudo fdisk /dev/sda 命令进入 fdisk 工具。
使用 p 命令显示分区表，找到根分区 /dev/mapper/centos-root 的分区编号（通常是 2）。
使用 d 命令删除根分区，然后使用 n 命令创建一个新的分区。
按照提示输入分区的起始扇区和大小，起始扇区可以直接按回车键使用默认值。
使用 t 命令将新分区的类型设置为 8e （Linux LVM）。
使用 p 命令检查分区表是否正确。
使用 w 命令保存分区表并退出 fdisk 工具。
使用 sudo partprobe 命令更新内核分区信息。
使用 sudo pvresize /dev/sda2 命令将物理卷扩大到新的分区大小。
使用 sudo lvextend -r /dev/mapper/centos-root /dev/sda2 命令将逻辑卷扩大到物理卷的大小。
执行完上述步骤后，你的根分区就会扩大到新的空间大小。
```



解决步骤

```sh
好的，具体的步骤如下：

首先，使用 sudo fdisk /dev/sda 命令进入 fdisk 工具。

[root@localhost ~]# sudo fdisk /dev/sda
使用 p 命令显示分区表，找到根分区 /dev/mapper/centos-root 的分区编号（通常是 2）。

Command (m for help): p

Disk /dev/sda: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x00000000

   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *        2048     1026047      512000   83  Linux
/dev/sda2         1026048    41943039    20458496   8e  Linux LVM
使用 d 命令删除根分区，然后使用 n 命令创建一个新的分区。

Command (m for help): d
Partition number (1,2, default 2): 2
Partition 2 is deleted

Command (m for help): n
Partition type:
   p   primary (1 primary, 0 extended, 3 free)
   e   extended
Select (default p): p
Partition number (2-4, default 2): 2
First sector (1026048-41943039, default 1026048):
Using default value 1026048
Last sector, +sectors or +size{K,M,G} (1026048-41943039, default 41943039):
Using default value 41943039
Partition 2 of type Linux and of size 19.5 GiB is set
按照提示输入分区的起始扇区和大小，起始扇区可以直接按回车键使用默认值。

使用 t 命令将新分区的类型设置为 8e （Linux LVM）。

Command (m for help): t
Partition number (1,2, default 2): 2
Hex code (type L to list all codes): 8e
Changed type of partition 'Linux' to 'Linux LVM'
使用 p 命令检查分区表是否正确。

Command (m for help): p

Disk /dev/sda: 21.5 GB, 21474836480 bytes, 41943040 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk label type: dos
Disk identifier: 0x00000000

   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *        2048     1026047      512000   83  Linux
/dev/sda2         1026048    41943039    20458496   8e  Linux LVM
使用 w 命令保存分区表并退出 fdisk 工具。

Command (m for help): w
The partition table has been altered!

Calling ioctl() to re-read partition table.

WARNING: Re-reading the partition table failed with error 16: Device or resource busy.
The kernel still uses the old table. The new table will be used at
the next reboot or after you run partprobe(8) or kpartx(8)
Syncing disks.
使用 sudo partprobe 命令更新内核分区信息。

[root@localhost ~]# sudo partprobe
使用 sudo pvresize /dev/sda2 命令将物理卷扩大到新的分区大小。

[root@localhost ~]# sudo pvresize /dev/sda2
Physical volume "/dev/sda2" changed
1 physical volume(s) resized / 0 physical volume(s) not resized
使用 sudo lvextend -r /dev/mapper/centos-root /dev/sda2 命令将逻辑卷扩大到物理卷的大小。

[root@localhost ~]# sudo lvextend -r /dev/mapper/centos-root /dev/sda2
Size of logical volume centos/root changed from 16.00 GiB (4096 extents) to 19.50 GiB (4992 extents).
Logical volume centos/root successfully resized.
meta-data=/dev/mapper/centos-root isize=512    agcount=4, agsize=1048576 blks
         =                       sectsz=512   attr=2, projid32bit=1
         =                       crc=1        finobt=0 spinodes=0
data     =                       bsize=4096   blocks=4194304, imaxpct=25
         =                       sunit=0      swidth=0 blks
naming   =version 2              bsize=4096   ascii-ci=0 ftype=1
log      =internal log           bsize=4096   blocks=2560, version=2
         =                       sectsz=512   sunit=0 blks, lazy-count=1
realtime =none                   extsz=4096   blocks=0, rtextents=0
data blocks changed from 4194304 to 5091328
最后，使用 df -h 命令检查根分区是否已经扩大。

[root@localhost ~]# df -h
Filesystem               Size  Used Avail Use% Mounted on
devtmpfs                 488M     0  488M   0% /dev
tmpfs                    497M     0  497M   0% /dev/shm
tmpfs                    497M  6.5M  491M   2% /run
tmpfs                    497M     0  497M   0% /sys/fs/cgroup
/dev/mapper/centos-root   20G   17G  3.4G  84% /
/dev/sda1                497M  190M  308M  39% /boot
tmpfs                    100M     0  100M   0% /run/user/0
现在你的根分区已经扩大到 20G，空间问题已经解决。
```







# 01-使用docker部署组件

## mysql 8.0.32

```sh
docker run --restart=always -d --name mschat-mysql -p 3306:3306 -v /miaoseng/mysql/data:/var/lib/mysql -v /miaoseng/mysql/conf:/etc/mysql/conf.d -v /miaoseng/mysql/logs:/data/mysql/logs -e MYSQL_ROOT_PASSWORD=msken2023 mysql:8.0.32

```

```sh
docker run --restart=always -d --name mysql_dev -p 3306:3306 -v /deploy/mysql_dev/data:/var/lib/mysql -v /deploy/mysql_dev/conf:/etc/mysql/conf.d -v /deploy/mysql_dev/logs:/data/mysql/logs -e MYSQL_ROOT_PASSWORD=123456 mysql:8.0.32

```



## redis

```sh
docker run --restart=always --log-opt max-size=100m --log-opt max-file=2 -p 6379:6379 --name mschat-redis 
-v /miaoseng/redis/msredis.conf:/etc/redis/redis.conf 
-v /miaoseng/redis/data:/data 
-d redis redis-server /etc/redis/redis.conf  --appendonly yes  
--requirepass mslyken2023
```



```sh
docker run --restart=always --log-opt max-size=100m --log-opt max-file=2 -p 6379:6379 --name redis_dev 
-v /deploy/redis_dev/myredis.conf:/etc/redis/redis.conf 
-v /deploy/redis_dev/data:/data 
-d redis redis-server /etc/redis/redis.conf  --appendonly yes  
--requirepass 123456
```



## nginx 

https://blog.csdn.net/S_ZaiJiangHu/article/details/126838279

![image-20230411090826024](%E5%AD%A6%E4%B9%A0%E6%8F%90%E5%8D%87%E8%B7%AF%E7%BA%BF.assets/image-20230411090826024.png)

```sh
01
在/deploy/nacos_dev 下创建 html logs conf文件夹
docker run -d nginx
02
docker ps 
docker cp nginx[id]:/etc/nginx/nginx.conf /deploy/nacos_dev/conf
03
docker rm -f 3e1e8409d8a5
04
docker run --restart=always -d -p 80:80 --name nginx_dev \
-v /deploy/nginx_dev/html:/usr/share/nginx/html \
-v /deploy/nginx_dev/conf/nginx.conf:/etc/nginx/nginx.conf \
-v /deploy/nginx_dev/logs:/var/log/nginx nginx

```

```sh
docker run --restart=always -d -p 80:80 --name nginx \
-v /root/dockerswarm/nginx/html:/usr/share/nginx/html \
-v /root/dockerswarm/nginx/conf/nginx.conf:/etc/nginx/nginx.conf \
-v /root/dockerswarm/nginx/logs:/var/log/nginx nginx
```





## nacos 2.0.3

==注意==Nacos1.x的搭建方式和2.x的方式，基本一致，相比1.X新增了gRPC的通信方式，因此需要增加2个端口。新增端口是在配置的主端口(server.port)基础上，进行一定偏移量自动生成（分别偏移了1000和1001)，nacos默认的端口为8848，偏移后的新增端口为9848与9849。

教程：

https://blog.csdn.net/zhuocailing3390/article/details/123058374?ops_request_misc=&request_id=&biz_id=102&utm_term=docker%E9%83%A8%E7%BD%B2nacos%E5%8D%95%E6%9C%BA&utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-123058374.142^v82^insert_down38,201^v4^add_ask,239^v2^insert_chatgpt&spm=1018.2226.3001.4187



1.创建挂载目录

2.先不进行任何配置直接启动一个`nacos`容器，然后将容器中的`data、conf、log、bin`拷贝到`/deploy/nacos_dev`目录下。

```sh
docker run --name nacos-server -d nacos/nacos-server:2.0.3
```

3.拷贝

```sh
docker cp nacos-server:/home/nacos/conf /deploy/nacos_dev
docker cp nacos-server:/home/nacos/logs /deploy/nacos_dev
docker cp nacos-server:/home/nacos/bin /deploy/nacos_dev
docker cp nacos-server:/home/nacos/data /deploy/nacos_dev

```

![image-20230412091138884](%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2.assets/image-20230412091138884.png)



4.  `vim application.properties` ：修改为mysql持久化 ==mysql版本为8.0.32==

5.  创建表：从`github`获取建表语句，地址：https://github.com/alibaba/nacos/blob/master/config/src/main/resources/META-INF/nacos-db.sql

6.  配置docker-startup.sh(一定要设置这里，不然服务器gg当我没说)

```sh
vim deploy/nacos_dev/bin/docker-startup.sh
```

```sh
JAVA_OPT="${JAVA_OPT} -Xms512m -Xmx512m -Xmn512m"

```

![image-20230412091937547](%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2.assets/image-20230412091937547.png)

![image-20230419101223198](%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2.assets/image-20230419101223198.png)

6.挂载启动容器

`docker --privileged=true 参数作用`

大约在0.6版，privileged被引入docker。
使用该参数，container内的root拥有真正的root权限。
否则，container内的root只是外部的一个普通用户权限。
privileged启动的容器，可以看到很多host上的设备，并且可以执行mount。
甚至允许你在docker容器中启动docker容器。

```sh
docker  run --name nacos_dev_standalone -d --privileged=true --restart=always -p 8848:8848 -p 9848:9848 -p 9849:9849 -e MODE=standalone -e PREFER_HOST_MODE=hostname -v /deploy/nacos_dev/logs:/home/nacos/logs 
-v /deploy/nacos_dev/data:/home/nacos/data -v /deploy/nacos_dev/conf:/home/nacos/conf 
-v /deploy/nacos_dev/bin:/home/nacos/bin nacos/nacos-server:2.0.3

```



```sh
docker cp nacos-server:/home/nacos/conf /miaoseng/nacos
docker cp nacos-server:/home/nacos/logs /miaoseng/nacos
docker cp nacos-server:/home/nacos/bin /miaoseng/nacos
docker cp nacos-server:/home/nacos/data /miaoseng/nacos
```

```sh
docker  run --name nacos_dev_standalone -d --privileged=true --restart=always -p 8848:8848 -p 9848:9848 -p 9849:9849 -e MODE=standalone -e PREFER_HOST_MODE=hostname -v /miaoseng/nacos/logs:/home/nacos/logs 
-v /miaoseng/nacos/data:/home/nacos/data -v /miaoseng/nacos/conf:/home/nacos/conf 
-v /miaoseng/nacos/bin:/home/nacos/bin nacos/nacos-server:2.0.3
```







### application.properties 样例

```yml
#
# Copyright 1999-2021 Alibaba Group Holding Ltd.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

#*************** Spring Boot Related Configurations ***************#
### Default web context path:
server.servlet.contextPath=/nacos
### Default web server port:
server.port=8848

#*************** Network Related Configurations ***************#
### If prefer hostname over ip for Nacos server addresses in cluster.conf:
# nacos.inetutils.prefer-hostname-over-ip=false

### Specify local server's IP:
# nacos.inetutils.ip-address=


#*************** Config Module Related Configurations ***************#
### If use MySQL as datasource:
spring.datasource.platform=mysql

### Count of DB:
db.num=1

### Connect URL of DB:
db.url.0=jdbc:mysql://192.168.87.128:3306/ry-config?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC
db.user.0=root
db.password.0=123456

### Connection pool configuration: hikariCP
db.pool.config.connectionTimeout=30000
db.pool.config.validationTimeout=10000
db.pool.config.maximumPoolSize=20
db.pool.config.minimumIdle=2

#*************** Naming Module Related Configurations ***************#
### Data dispatch task execution period in milliseconds: Will removed on v2.1.X, replace with nacos.core.protocol.distro.data.sync.delayMs
# nacos.naming.distro.taskDispatchPeriod=200

### Data count of batch sync task: Will removed on v2.1.X. Deprecated
# nacos.naming.distro.batchSyncKeyCount=1000

### Retry delay in milliseconds if sync task failed: Will removed on v2.1.X, replace with nacos.core.protocol.distro.data.sync.retryDelayMs
# nacos.naming.distro.syncRetryDelay=5000

### If enable data warmup. If set to false, the server would accept request without local data preparation:
# nacos.naming.data.warmup=true

### If enable the instance auto expiration, kind like of health check of instance:
# nacos.naming.expireInstance=true

### will be removed and replaced by `nacos.naming.clean` properties
nacos.naming.empty-service.auto-clean=true
nacos.naming.empty-service.clean.initial-delay-ms=50000
nacos.naming.empty-service.clean.period-time-ms=30000

### Add in 2.0.0
### The interval to clean empty service, unit: milliseconds.
# nacos.naming.clean.empty-service.interval=60000

### The expired time to clean empty service, unit: milliseconds.
# nacos.naming.clean.empty-service.expired-time=60000

### The interval to clean expired metadata, unit: milliseconds.
# nacos.naming.clean.expired-metadata.interval=5000

### The expired time to clean metadata, unit: milliseconds.
# nacos.naming.clean.expired-metadata.expired-time=60000

### The delay time before push task to execute from service changed, unit: milliseconds.
# nacos.naming.push.pushTaskDelay=500

### The timeout for push task execute, unit: milliseconds.
# nacos.naming.push.pushTaskTimeout=5000

### The delay time for retrying failed push task, unit: milliseconds.
# nacos.naming.push.pushTaskRetryDelay=1000

### Since 2.0.3
### The expired time for inactive client, unit: milliseconds.
# nacos.naming.client.expired.time=180000

#*************** CMDB Module Related Configurations ***************#
### The interval to dump external CMDB in seconds:
# nacos.cmdb.dumpTaskInterval=3600

### The interval of polling data change event in seconds:
# nacos.cmdb.eventTaskInterval=10

### The interval of loading labels in seconds:
# nacos.cmdb.labelTaskInterval=300

### If turn on data loading task:
# nacos.cmdb.loadDataAtStart=false


#*************** Metrics Related Configurations ***************#
### Metrics for prometheus
#management.endpoints.web.exposure.include=*

### Metrics for elastic search
management.metrics.export.elastic.enabled=false
#management.metrics.export.elastic.host=http://localhost:9200

### Metrics for influx
management.metrics.export.influx.enabled=false
#management.metrics.export.influx.db=springboot
#management.metrics.export.influx.uri=http://localhost:8086
#management.metrics.export.influx.auto-create-db=true
#management.metrics.export.influx.consistency=one
#management.metrics.export.influx.compressed=true

#*************** Access Log Related Configurations ***************#
### If turn on the access log:
server.tomcat.accesslog.enabled=true

### The access log pattern:
server.tomcat.accesslog.pattern=%h %l %u %t "%r" %s %b %D %{User-Agent}i %{Request-Source}i

### The directory of access log:
server.tomcat.basedir=

#*************** Access Control Related Configurations ***************#
### If enable spring security, this option is deprecated in 1.2.0:
#spring.security.enabled=false

### The ignore urls of auth, is deprecated in 1.2.0:
nacos.security.ignore.urls=/,/error,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-ui/public/**,/v1/auth/**,/v1/console/health/**,/actuator/**,/v1/console/server/**

### The auth system to use, currently only 'nacos' and 'ldap' is supported:
nacos.core.auth.system.type=nacos

### If turn on auth system:
nacos.core.auth.enabled=false

### worked when nacos.core.auth.system.type=ldap，{0} is Placeholder,replace login username
# nacos.core.auth.ldap.url=ldap://localhost:389
# nacos.core.auth.ldap.userdn=cn={0},ou=user,dc=company,dc=com

### The token expiration in seconds:
nacos.core.auth.default.token.expire.seconds=18000

### The default token:
nacos.core.auth.default.token.secret.key=SecretKey012345678901234567890123456789012345678901234567890123456789

### Turn on/off caching of auth information. By turning on this switch, the update of auth information would have a 15 seconds delay.
nacos.core.auth.caching.enabled=true

### Since 1.4.1, Turn on/off white auth for user-agent: nacos-server, only for upgrade from old version.
nacos.core.auth.enable.userAgentAuthWhite=false

### Since 1.4.1, worked when nacos.core.auth.enabled=true and nacos.core.auth.enable.userAgentAuthWhite=false.
### The two properties is the white list for auth and used by identity the request from other server.
nacos.core.auth.server.identity.key=serverIdentity
nacos.core.auth.server.identity.value=security

#*************** Istio Related Configurations ***************#
### If turn on the MCP server:
nacos.istio.mcp.server.enabled=false

#*************** Core Related Configurations ***************#

### set the WorkerID manually
# nacos.core.snowflake.worker-id=

### Member-MetaData
# nacos.core.member.meta.site=
# nacos.core.member.meta.adweight=
# nacos.core.member.meta.weight=

### MemberLookup
### Addressing pattern category, If set, the priority is highest
# nacos.core.member.lookup.type=[file,address-server]
## Set the cluster list with a configuration file or command-line argument
# nacos.member.list=192.168.16.101:8847?raft_port=8807,192.168.16.101?raft_port=8808,192.168.16.101:8849?raft_port=8809
## for AddressServerMemberLookup
# Maximum number of retries to query the address server upon initialization
# nacos.core.address-server.retry=5
## Server domain name address of [address-server] mode
# address.server.domain=jmenv.tbsite.net
## Server port of [address-server] mode
# address.server.port=8080
## Request address of [address-server] mode
# address.server.url=/nacos/serverlist

#*************** JRaft Related Configurations ***************#

### Sets the Raft cluster election timeout, default value is 5 second
# nacos.core.protocol.raft.data.election_timeout_ms=5000
### Sets the amount of time the Raft snapshot will execute periodically, default is 30 minute
# nacos.core.protocol.raft.data.snapshot_interval_secs=30
### raft internal worker threads
# nacos.core.protocol.raft.data.core_thread_num=8
### Number of threads required for raft business request processing
# nacos.core.protocol.raft.data.cli_service_thread_num=4
### raft linear read strategy. Safe linear reads are used by default, that is, the Leader tenure is confirmed by heartbeat
# nacos.core.protocol.raft.data.read_index_type=ReadOnlySafe
### rpc request timeout, default 5 seconds
# nacos.core.protocol.raft.data.rpc_request_timeout_ms=5000

#*************** Distro Related Configurations ***************#

### Distro data sync delay time, when sync task delayed, task will be merged for same data key. Default 1 second.
# nacos.core.protocol.distro.data.sync.delayMs=1000

### Distro data sync timeout for one sync data, default 3 seconds.
# nacos.core.protocol.distro.data.sync.timeoutMs=3000

### Distro data sync retry delay time when sync data failed or timeout, same behavior with delayMs, default 3 seconds.
# nacos.core.protocol.distro.data.sync.retryDelayMs=3000

### Distro data verify interval time, verify synced data whether expired for a interval. Default 5 seconds.
# nacos.core.protocol.distro.data.verify.intervalMs=5000

### Distro data verify timeout for one verify, default 3 seconds.
# nacos.core.protocol.distro.data.verify.timeoutMs=3000

### Distro data load retry delay when load snapshot data failed, default 30 seconds.
# nacos.core.protocol.distro.data.load.retryDelayMs=30000

```

### 持久化sql

```sql
CREATE TABLE `config_info` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',
  `data_id` varchar(255) NOT NULL COMMENT 'data_id',
  `group_id` varchar(255) DEFAULT NULL,
  `content` longtext NOT NULL COMMENT 'content',
  `md5` varchar(32) DEFAULT NULL COMMENT 'md5',
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `src_user` text COMMENT 'source user',
  `src_ip` varchar(50) DEFAULT NULL COMMENT 'source ip',
  `app_name` varchar(128) DEFAULT NULL,
  `tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段',
  `c_desc` varchar(256) DEFAULT NULL,
  `c_use` varchar(64) DEFAULT NULL,
  `effect` varchar(64) DEFAULT NULL,
  `type` varchar(64) DEFAULT NULL,
  `c_schema` text,
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_configinfo_datagrouptenant` (`data_id`,`group_id`,`tenant_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info';

/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = config_info_aggr   */
/******************************************/
CREATE TABLE `config_info_aggr` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',
  `data_id` varchar(255) NOT NULL COMMENT 'data_id',
  `group_id` varchar(255) NOT NULL COMMENT 'group_id',
  `datum_id` varchar(255) NOT NULL COMMENT 'datum_id',
  `content` longtext NOT NULL COMMENT '内容',
  `gmt_modified` datetime NOT NULL COMMENT '修改时间',
  `app_name` varchar(128) DEFAULT NULL,
  `tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_configinfoaggr_datagrouptenantdatum` (`data_id`,`group_id`,`tenant_id`,`datum_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='增加租户字段';


/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = config_info_beta   */
/******************************************/
CREATE TABLE `config_info_beta` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',
  `data_id` varchar(255) NOT NULL COMMENT 'data_id',
  `group_id` varchar(128) NOT NULL COMMENT 'group_id',
  `app_name` varchar(128) DEFAULT NULL COMMENT 'app_name',
  `content` longtext NOT NULL COMMENT 'content',
  `beta_ips` varchar(1024) DEFAULT NULL COMMENT 'betaIps',
  `md5` varchar(32) DEFAULT NULL COMMENT 'md5',
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `src_user` text COMMENT 'source user',
  `src_ip` varchar(50) DEFAULT NULL COMMENT 'source ip',
  `tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_configinfobeta_datagrouptenant` (`data_id`,`group_id`,`tenant_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_beta';

/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = config_info_tag   */
/******************************************/
CREATE TABLE `config_info_tag` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',
  `data_id` varchar(255) NOT NULL COMMENT 'data_id',
  `group_id` varchar(128) NOT NULL COMMENT 'group_id',
  `tenant_id` varchar(128) DEFAULT '' COMMENT 'tenant_id',
  `tag_id` varchar(128) NOT NULL COMMENT 'tag_id',
  `app_name` varchar(128) DEFAULT NULL COMMENT 'app_name',
  `content` longtext NOT NULL COMMENT 'content',
  `md5` varchar(32) DEFAULT NULL COMMENT 'md5',
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  `src_user` text COMMENT 'source user',
  `src_ip` varchar(50) DEFAULT NULL COMMENT 'source ip',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_configinfotag_datagrouptenanttag` (`data_id`,`group_id`,`tenant_id`,`tag_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_info_tag';

/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = config_tags_relation   */
/******************************************/
CREATE TABLE `config_tags_relation` (
  `id` bigint(20) NOT NULL COMMENT 'id',
  `tag_name` varchar(128) NOT NULL COMMENT 'tag_name',
  `tag_type` varchar(64) DEFAULT NULL COMMENT 'tag_type',
  `data_id` varchar(255) NOT NULL COMMENT 'data_id',
  `group_id` varchar(128) NOT NULL COMMENT 'group_id',
  `tenant_id` varchar(128) DEFAULT '' COMMENT 'tenant_id',
  `nid` bigint(20) NOT NULL AUTO_INCREMENT,
  PRIMARY KEY (`nid`),
  UNIQUE KEY `uk_configtagrelation_configidtag` (`id`,`tag_name`,`tag_type`),
  KEY `idx_tenant_id` (`tenant_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='config_tag_relation';

/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = group_capacity   */
/******************************************/
CREATE TABLE `group_capacity` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键ID',
  `group_id` varchar(128) NOT NULL DEFAULT '' COMMENT 'Group ID，空字符表示整个集群',
  `quota` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值',
  `usage` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '使用量',
  `max_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值',
  `max_aggr_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数，，0表示使用默认值',
  `max_aggr_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值',
  `max_history_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '最大变更历史数量',
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_group_id` (`group_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='集群、各Group容量信息表';

/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = his_config_info   */
/******************************************/
CREATE TABLE `his_config_info` (
  `id` bigint(64) unsigned NOT NULL,
  `nid` bigint(20) unsigned NOT NULL AUTO_INCREMENT,
  `data_id` varchar(255) NOT NULL,
  `group_id` varchar(128) NOT NULL,
  `app_name` varchar(128) DEFAULT NULL COMMENT 'app_name',
  `content` longtext NOT NULL,
  `md5` varchar(32) DEFAULT NULL,
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,
  `src_user` text,
  `src_ip` varchar(50) DEFAULT NULL,
  `op_type` char(10) DEFAULT NULL,
  `tenant_id` varchar(128) DEFAULT '' COMMENT '租户字段',
  PRIMARY KEY (`nid`),
  KEY `idx_gmt_create` (`gmt_create`),
  KEY `idx_gmt_modified` (`gmt_modified`),
  KEY `idx_did` (`data_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='多租户改造';


/******************************************/
/*   数据库全名 = nacos_config   */
/*   表名称 = tenant_capacity   */
/******************************************/
CREATE TABLE `tenant_capacity` (
  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT '主键ID',
  `tenant_id` varchar(128) NOT NULL DEFAULT '' COMMENT 'Tenant ID',
  `quota` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '配额，0表示使用默认值',
  `usage` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '使用量',
  `max_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个配置大小上限，单位为字节，0表示使用默认值',
  `max_aggr_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '聚合子配置最大个数',
  `max_aggr_size` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值',
  `max_history_count` int(10) unsigned NOT NULL DEFAULT '0' COMMENT '最大变更历史数量',
  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '修改时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_tenant_id` (`tenant_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='租户容量信息表';


CREATE TABLE `tenant_info` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',
  `kp` varchar(128) NOT NULL COMMENT 'kp',
  `tenant_id` varchar(128) default '' COMMENT 'tenant_id',
  `tenant_name` varchar(128) default '' COMMENT 'tenant_name',
  `tenant_desc` varchar(256) DEFAULT NULL COMMENT 'tenant_desc',
  `create_source` varchar(32) DEFAULT NULL COMMENT 'create_source',
  `gmt_create` bigint(20) NOT NULL COMMENT '创建时间',
  `gmt_modified` bigint(20) NOT NULL COMMENT '修改时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `uk_tenant_info_kptenantid` (`kp`,`tenant_id`),
  KEY `idx_tenant_id` (`tenant_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT='tenant_info';

CREATE TABLE `users` (
	`username` varchar(50) NOT NULL PRIMARY KEY,
	`password` varchar(500) NOT NULL,
	`enabled` boolean NOT NULL
);

CREATE TABLE `roles` (
	`username` varchar(50) NOT NULL,
	`role` varchar(50) NOT NULL,
	UNIQUE INDEX `idx_user_role` (`username` ASC, `role` ASC) USING BTREE
);

CREATE TABLE `permissions` (
    `role` varchar(50) NOT NULL,
    `resource` varchar(255) NOT NULL,
    `action` varchar(8) NOT NULL,
    UNIQUE INDEX `uk_role_permission` (`role`,`resource`,`action`) USING BTREE
);

INSERT INTO users (username, password, enabled) VALUES ('nacos', '$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu', TRUE);

INSERT INTO roles (username, role) VALUES ('nacos', 'ROLE_ADMIN');

```



## Nacos1.4.2部署教程

https://blog.csdn.net/yx444535180/article/details/126096618 结合2.0.3部署即可

```sh
docker cp nacos:/home/nacos/conf /miaoseng/nacos
docker cp nacos:/home/nacos/logs /miaoseng/nacos
docker cp nacos:/home/nacos/bin /miaoseng/nacos
docker cp nacos:/home/nacos/data /miaoseng/nacos
```





```sh
docker run -d \
-e MODE=standalone \
-e PREFER_HOST_MODE=hostname \
 -v /miaoseng/nacos/logs:/home/nacos/logs \
 -v /miaoseng/nacos/data:/home/nacos/data \
 -v /miaoseng/nacos/conf:/home/nacos/conf \
 -v /miaoseng/nacos/bin:/home/nacos/bin \
-p 8848:8848 \
--name nacos \
--restart=always \
nacos/nacos-server:1.4.2

```





# elasticsearch 7.6.2

教程： https://blog.csdn.net/congge_study/article/details/127818225

https://blog.csdn.net/weixin_45915507/article/details/119424610



整合SpringBoot教程：https://blog.csdn.net/weixin_47409774/article/details/123402714



创建挂载目录及写入文件

```sh
# 创建存储数据的目录
mkdir -p /deploy/elasticsearch_dev/config
mkdir -p /deploy/elasticsearch_dev/data
# 随便外网都可以访问它
cd /deploy/elasticsearch_dev/config
# 写入文件
echo "http.host: 0.0.0.0" >> /deploy/elasticsearch_dev/config/elasticsearch.yml

# 查看
[root@localhost config]# cat elasticsearch.yml 
http.host: 0.0.0.0
[root@localhost config]# 


```

拉取镜像

```sh
docker pull elasticsearch:7.6.2
```

执行下面的命令进行安装

```sh
docker run --name elasticsearch_dev --restart=always -p 9200:9200 -p 9300:9300 \
-e "discovery.type=single-node" \
-e ES_JAVA_OPTS="-Xms512m -Xmx512m" \
-v /deploy/elasticsearch_dev/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \
-v /deploy/elasticsearch_dev/data:/usr/share/elasticsearch/data \
-v /deploy/elasticsearch_dev/plugins:/usr/share/elasticsearch/plugins \
-d elasticsearch:7.6.2

```



常用命令

```sh
netstat -tanlp 查看启动进程和端口号

sudo kill 进程号

source命令的作用：

刷新当前的shell环境
在当前环境中使用source执行shell脚本
从脚本中导入一个shell功能函数
从另一个shell脚本中读取变量
```







修改权限

```sh
[root@localhost elasticsearch_dev]# pwd
/deploy/elasticsearch_dev
[root@localhost elasticsearch_dev]# chmod -R 777 /deploy/elasticsearch_dev
[root@localhost elasticsearch_dev]# ll
total 0
drwxrwxrwx. 2 root root 31 Apr 16 09:44 config
drwxrwxrwx. 2 root root  6 Apr 16 09:39 data
drwxrwxrwx. 2 root root  6 Apr 16 09:47 plugins
[root@localhost elasticsearch_dev]# 

```

关于 `ll`指令可以看这个 https://blog.csdn.net/qq_46224953/article/details/122765817

```sh
0-9 位说明
第0 位确定文件类型(d, - , l , c , b)
-是文件

l 是链接（link），相当于windows 的快捷方式

d 是目录，相当于windows 的文件夹

c 是字符设备文件，鼠标，键盘

b 是块设备，比如硬盘
第1-3 位确定所有者（该文件的所有者）拥有该文件的权限。—User

第4-6 位确定所属组（同用户组的）拥有该文件的权限，—Group

第7-9 位确定其他用户拥有该文件的权限 —Other

rwx分别是可读、可写、可执行（execute）

1：子目录数（注意：只记录子目录数，不会把文件数也算进去，且会将隐藏目录计算在内）

root：所有者

root：所在组

1896：文件大小（字节），如果是文件夹，显示4096字节

日期：最后修改日期
```



重启es

```sh
docker restart b76d3ebf2100

```

查看是否安装成功

```sh
http://192.168.87.128:9200/


{
  "name" : "b76d3ebf2100",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "EJ_BoUkBQ1Gp6buXVVSdAA",
  "version" : {
    "number" : "7.6.2",
    "build_flavor" : "default",
    "build_type" : "docker",
    "build_hash" : "ef48eb35cf30adf4db14086e8aabd07ef6fb113f",
    "build_date" : "2020-03-26T06:34:37.794943Z",
    "build_snapshot" : false,
    "lucene_version" : "8.4.0",
    "minimum_wire_compatibility_version" : "6.8.0",
    "minimum_index_compatibility_version" : "6.0.0-beta1"
  },
  "tagline" : "You Know, for Search"
}
```



# Kibana 7.6.2

参考： https://blog.csdn.net/gaohuanjie/article/details/127926055

```sh
docker pull kibana:7.6.2
# 创建挂载目录
mkdir -p /deploy/kibana_dev/config
vi /deploy/kibana_dev/config/kibana.yml

```



```sh
#设置Kibana映射端口
server.port: 5601

#设置网关地址
server.host: "0.0.0.0"

#设置Kibana实例对外展示的名称
server.name: "kibana"

#设置ES集群地址
elasticsearch.hosts: ["http://192.168.87.128:9200","http://192.168.1.100:9202","http://192.168.1.100:9203"]

#设置请求超时时长
elasticsearch.requestTimeout: 120000

#设置页面语言
i18n.locale: "zh-CN"

```



```sh
docker run -d -p 5601:5601 -v /deploy/kibana_dev/config/kibana.yml:/usr/share/kibana/config/kibana.yml --restart=always --name kibana_dev  kibana:7.6.2

```





# ik分词器 7.6.2

在tool压缩包里面有； D:\Tools 7.6.2



下面这个不行

https://github.com/medcl/elasticsearch-analysis-ik/releases/tag/v7.16.2



把压缩包放到 `/deploy/elasticsearch_dev/plugins`

解压

```sh
cd /deploy/elasticsearch_dev/plugins
# 先安装unzip工具
yum install -y unzip
# 解压
unzip elasticsearch-analysis-ik-7.16.2.zip 
```

解压完后把压缩包去掉，不然报错

![image-20230416103603183](%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2.assets/image-20230416103603183.png)





查看时候装成功

```sh
[root@localhost plugins]# docker exec -it b76d3ebf2100 /bin/bash
[root@b76d3ebf2100 elasticsearch]# cd /bin
[root@b76d3ebf2100 bin]# elasticsearch-plugin list

#成功
[root@b76d3ebf2100 bin]# elasticsearch-plugin list
ik

```



# Elasticsearch-Head插件

下载镜像

```bash
docker pull mobz/elasticsearch-head:5

```

启动容器

```bash
docker run -d -p 9100:9100 --name es-head --restart=always mobz/elasticsearch-head:5
# 查看容器
docker ps 
```



原文链接：https://blog.csdn.net/ak739105231/article/details/107681917解决：elasticsearch-head连接不上es的问题（跨域问题）
#进入es容器中

```sh
 docker exec -it 314f6ccb43c0 /bin/bash
```

前面已经挂载出来，不用进入容器修改了
在elasticsearch.yml 中添加

```sh
http.cors.enabled: true
http.cors.allow-origin: "*"
```

重启es

![image-20230416111353893](%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2.assets/image-20230416111353893.png)

在ik分词器里自定义词库

![image-20230416111831205](%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2.assets/image-20230416111831205.png)



在nginxhtml挂载目录里面创建extend.txt文件夹

![image-20230416112428949](%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2.assets/image-20230416112428949.png)

![image-20230416112451685](%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2.assets/image-20230416112451685.png)

修改远程扩展字典地址

```xml
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE properties SYSTEM "http://java.sun.com/dtd/properties.dtd">
<properties>
	<comment>IK Analyzer 扩展配置</comment>
	<!--用户可以在这里配置自己的扩展字典 -->
	<entry key="ext_dict"></entry>
	 <!--用户可以在这里配置自己的扩展停止词字典-->
	<entry key="ext_stopwords"></entry>

	<!--用户可以在这里配置远程扩展字典 -->
	<entry key="remote_ext_dict">http://192.168.87.128/es/extend.txt</entry>

	<!--用户可以在这里配置远程扩展字典 -->
	<!-- <entry key="remote_ext_dict">words_location</entry> -->
	<!--用户可以在这里配置远程扩展停止词字典-->
	<!-- <entry key="remote_ext_stopwords">words_location</entry> -->
</properties>
```



重启es



# java环境linux下安装

https://blog.csdn.net/ddsheng1128/article/details/85544727





# kafka

https://blog.csdn.net/weixin_32555599/article/details/120990052



# docker-compose安装

https://www.jb51.cc/docker-tutorial/1187541.html

安装 Docker Compose 可以通过下面命令[自动](https://www.jb51.cc/tag/zidong/)下载适应版本的 Compose，并为安装脚本[添加](https://www.jb51.cc/tag/tianjia/)执行权限

```bash
# 下载 docker-compose wget https://github.com/docker/compose/releases/download/1.26.0/docker-compose-Linux-x86_64# 移到 /usr/local/bin/docker-composesudo mv docker-compose-Linux-x86_64 /usr/local/bin/docker-compose# 给 docker-compose 执行权限sudo chmod +x /usr/local/bin/docker-compose
```

查看安装是否成功：

```bash
docker-compose -v
```

# 11111
